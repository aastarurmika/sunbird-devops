- name: ensure backup dir exists
  file: path="{{ postgresql_backup_dir }}" state=directory owner={{ postgresql_user }} group={{ postgresql_user }}

- set_fact:
    postgresql_backup_gzip_file_name: "competency_postgresql_backup_{{ lookup('pipe', 'date +%Z-%Y-%m-%d-%H-%M-%S') }}.sql.gz"

- set_fact:
    postgresql_backup_gzip_file_path: "{{ postgresql_backup_dir }}/{{ postgresql_backup_gzip_file_name }}"
    
    
- name: Save backup
  command: bash -lc "docker exec {{ postgres_container_name }} pg_dump  | gzip > {{ postgresql_backup_gzip_file_path }}"
  become_user: "{{ postgresql_user }}"
  async: 3600
  poll: 10



- name: upload file to aws s3
  include_role:
    name: aws-cloud-storage
    tasks_from: upload.yml
  vars:
    s3_bucket_name: "{{ cloud_storage_postgresqlbackup_bucketname }}"
    aws_access_key_id: "{{ cloud_management_storage_accountname }}"
    aws_secret_access_key: "{{ cloud_management_storage_secret }}"
    aws_default_region: "{{ cloud_public_storage_region }}"
    local_file_or_folder_path: "{{ postgresql_backup_gzip_file_path }}"
    s3_path: "{{ cloud_storage_postgresqlbackup_foldername }}/{{ postgresql_backup_gzip_file_name }}"
  when: cloud_service_provider == "aws"
     


- name: clean up backup dir after upload
  file: path="{{ postgresql_backup_dir }}" state=absent
